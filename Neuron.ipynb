{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score,precision_score,confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "import time \n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams['figure.figsize'] = [9, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading the dataset then shuffle and split it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Train data and its percentage out of all: 7000, 70.0%\n",
      "Count of Test data and its percentage out of all: 2000, 20.0%\n",
      "Count of Validation data and its percentage out of all: 1000, 10.0%\n",
      "Shape Train: (7000, 2)\n"
     ]
    }
   ],
   "source": [
    "with open('dataset-nonlinear.npy', 'rb') as f:\n",
    "    dataset = np.load(f)\n",
    "    np.random.shuffle(dataset)\n",
    "    \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:2], dataset[:,2:3], test_size=0.2,stratify=dataset[:,2:3])\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=0.125, stratify=Y_train)\n",
    "\n",
    "print(\"Count of Train data and its percentage out of all: {0}, {1}%\".format(X_train.shape[0],round(X_train.shape[0]/dataset.shape[0]*100,2)))\n",
    "print(\"Count of Test data and its percentage out of all: {0}, {1}%\".format(X_test.shape[0],round(X_test.shape[0]/dataset.shape[0]*100,2)))\n",
    "print(\"Count of Validation data and its percentage out of all: {0}, {1}%\".format(X_valid.shape[0],round(X_valid.shape[0]/dataset.shape[0]*100,2)))\n",
    "print(\"Shape Train:\",X_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateMetricsAndPlot(true_label, predicted_label,color=\"Blues\",text=\"\",path=\"\"):\n",
    "    CM = confusion_matrix(true_label, predicted_label)\n",
    "    acc = round(accuracy_score(true_label,predicted_label)*100,2)\n",
    "    precision = round(precision_score(true_label,predicted_label, average='macro'),2)\n",
    "    if text == \"\":\n",
    "        sns.heatmap(CM ,annot=True, cmap=color, fmt='g').set_title(\"Confusion Matrix |Accuracy={0}% |Precision={1}\".format(acc,precision))\n",
    "    else :\n",
    "        sns.heatmap(CM ,annot=True, cmap=color, fmt='g').set_title(\"Confusion Matrix |Accuracy={0}% |Precision={1} |{2}\".format(acc,precision,text))\n",
    "    \n",
    "    if path:\n",
    "        plt.savefig(path + '/confusion-matrix.png')\n",
    "        \n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):    \n",
    "    return x * (x > 0)\n",
    "\n",
    "def ReLU_Deriv(x):\n",
    "    return np.array(x > 0).astype(int)\n",
    "    \n",
    "def Sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def Sigmoid_Deriv(x):\n",
    "     return np.exp(-x)/((1 + np.exp(-x))**2)\n",
    "  \n",
    "def TanH(x):\n",
    "    return (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n",
    "\n",
    "def TanH_Deriv(x):\n",
    "    return 1-TanH(x)**2\n",
    "\n",
    "def Linear(x):\n",
    "    return x\n",
    "\n",
    "def Linear_Deriv(x):\n",
    "    return 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A custom class to simulation neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    weights = np.array([]) \n",
    "    weights_history = np.array([]) \n",
    "    \n",
    "    loss = np.array([]) \n",
    "    val_loss = np.array([]) \n",
    "    \n",
    "    miss_classified_train = np.array([])\n",
    "    miss_classified_valid = np.array([])\n",
    "    \n",
    "    acc = np.array([]) \n",
    "    val_acc = np.array([]) \n",
    "    \n",
    "    order = 1 \n",
    "    neuron_type = \"A\" \n",
    "    \n",
    "    def __init__(self,neuron_type=\"P\",order=1,activation=\"T\",features=2):\n",
    "        if not (order in [1,2] and neuron_type in [\"A\",\"P\"] and activation in [\"R\",\"S\",\"T\",\"L\"]):\n",
    "            raise ValueError(\"Given Parameter is not acceptable: order={0}, neuron type={1}, activation={2}\".format(order,neuron_type,activation))\n",
    "        \n",
    "        if features != 2 and order != 1:\n",
    "            raise ValueError(\"This model accept only features = 2 when order is set to 2\")\n",
    "        \n",
    "        self.features = features\n",
    "        if activation == \"R\":\n",
    "            self.activation = ReLU\n",
    "            self.activation_dx = ReLU_Deriv\n",
    "            self.activation_name = \"ReLU\"\n",
    "            \n",
    "        if activation == \"S\":\n",
    "            self.activation = Sigmoid\n",
    "            self.activation_dx = Sigmoid_Deriv\n",
    "            self.activation_name = \"Sigmoid\"\n",
    "            \n",
    "        if activation == \"T\":\n",
    "            self.activation = TanH\n",
    "            self.activation_dx = TanH_Deriv\n",
    "            self.activation_name = \"TanH\"\n",
    "            \n",
    "        if activation == \"L\":\n",
    "            self.activation = Linear\n",
    "            self.activation_dx = Linear_Deriv\n",
    "            self.activation_name = \"Linear\"\n",
    "        \n",
    "        self.order = order \n",
    "        self.neuron_type = neuron_type \n",
    "        self.reset()    \n",
    "    \n",
    "    def reset(self,RanDomRange = 0.5):\n",
    "        self.loss = np.array([])\n",
    "        self.val_loss = np.array([])\n",
    "        \n",
    "        self.acc = np.array([])\n",
    "        self.val_acc = np.array([])\n",
    "        \n",
    "        self.miss_classified_train = np.array([])\n",
    "        self.miss_classified_valid = np.array([])\n",
    "\n",
    "        if self.order == 1 :\n",
    "            self.weights = np.random.uniform(-RanDomRange,RanDomRange,3)\n",
    "\n",
    "        elif self.order == 2 :\n",
    "                self.weights = np.random.uniform(-RanDomRange,RanDomRange,6)\n",
    "                \n",
    "        self.weights_history = np.array([self.weights]) \n",
    "        \n",
    "    def kernel(self,x):\n",
    "        try :\n",
    "            x.T[0].shape[0]\n",
    "            x = x.T\n",
    "        except:\n",
    "            x = np.array([x])\n",
    "            x = x.T\n",
    "            \n",
    "        if self.order == 1:\n",
    "            return np.c_[ np.ones(x.T.shape[0]),x.T ].astype(np.float64)\n",
    "        \n",
    "        return np.array([[1]*x[0].shape[0], x[0], x[1], x[0]**2, x[1]**2, x[0]*x[1]]).astype(np.float64).T\n",
    "            \n",
    "        \n",
    "    def fit(self,x_train,y_train,x_valid,y_valid,x_test,y_test,learning_rate,epoch):\n",
    "        if x_train.shape[1] != self.features :\n",
    "            raise ValueError(\"Passed features count is not equal to setted features count\")\n",
    "        \n",
    "        self.reset()\n",
    "        x_train, x_valid = self.kernel(x_train),self.kernel(x_valid) \n",
    "        \n",
    "        for _ in range(epoch): \n",
    "            if self.neuron_type == \"P\":\n",
    "                for index in range(x_train.shape[0]):               \n",
    "                    predict = self.predict(np.array([x_train[index]]))[0]              \n",
    "                    update = learning_rate*(y_train[index]-predict)\n",
    "                    self.weights = self.weights + update*x_train[index]\n",
    "                    \n",
    "            elif self.neuron_type == \"A\":\n",
    "                for index in range(x_train.shape[0]):\n",
    "                    output = np.dot(x_train[index],self.weights)\n",
    "                    errors = y_train[index] - output\n",
    "                    self.weights += learning_rate*x_train[index]*errors  \n",
    "            \n",
    "            if self.neuron_type == \"P\":\n",
    "                self.loss = np.append(self.loss,mean_squared_error(y_train,self.predict(x_train)))\n",
    "                self.val_loss = np.append(self.val_loss,mean_squared_error(y_valid,self.predict(x_valid)))\n",
    "            else:                \n",
    "                self.loss = np.append(self.loss,mean_squared_error(y_train,np.dot(x_train,self.weights)))\n",
    "                self.val_loss = np.append(self.val_loss,mean_squared_error(y_valid,np.dot(x_valid,self.weights)))\n",
    "                \n",
    "            self.acc = np.append(self.acc,accuracy_score(y_train,self.predict(x_train)))\n",
    "            self.val_acc = np.append(self.val_acc,accuracy_score(y_valid,self.predict(x_valid)))      \n",
    "            \n",
    "            train_cm = confusion_matrix(y_train,self.predict(x_train))\n",
    "            valid_cm = confusion_matrix(y_valid,self.predict(x_valid))\n",
    "            self.miss_classified_train = np.append(self.miss_classified_train,sum([train_cm[0,1],train_cm[1,0]])/x_train.shape[0]) \n",
    "            self.miss_classified_valid = np.append(self.miss_classified_valid,sum([valid_cm[0,1],valid_cm[1,0]])/x_valid.shape[0]) \n",
    "                  \n",
    "            self.weights_history = np.vstack([self.weights_history, self.weights])\n",
    "            \n",
    "        self.save_results(learning_rate,x_test,y_test)            \n",
    "        \n",
    "\n",
    "            \n",
    "    def predict (self,x):\n",
    "        if x.shape[1] != self.weights.shape[0]: \n",
    "            x = self.kernel(x)\n",
    "            \n",
    "        output = np.dot(x,self.weights.T)\n",
    "        activate = np.array(list(map(self.activation,output)))  \n",
    "        \n",
    "        if self.activation_name == \"ReLU\" : return np.where(activate> 0, 1, -1)\n",
    "        if self.activation_name == \"Sigmoid\" : return np.where(activate> 0.5, 1, -1)\n",
    "        if self.activation_name == \"TanH\" : return np.where(activate> 0, 1, -1)\n",
    "        if self.activation_name == \"Linear\" : return np.where(activate> 0, 1, -1)\n",
    "        \n",
    "        \n",
    "    def save_results(self,learning_rate,x_test=None,y_test=None):\n",
    "        if self.loss.shape[0] == 0 :\n",
    "            return\n",
    "\n",
    "        file_path = datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\") \n",
    "        path = \"\"\n",
    "        \n",
    "        if self.neuron_type == \"P\": path += \"Perceptron - Order \"\n",
    "        else :                      path += \"Adaline - Order \"\n",
    "        \n",
    "        if self.order == 1 :  path += str(1)\n",
    "        else :                path += str(2)\n",
    "         \n",
    "        path += \" - \" + self.activation_name\n",
    "        path += \" - LR \" + str(learning_rate)         \n",
    "        path += \" - Iteration \" + str(self.loss.shape[0])  \n",
    "           \n",
    "        file_path += \" - \"+ path           \n",
    "        os.mkdir(file_path)\n",
    "        \n",
    "        with open(file_path + '/History.npy', 'wb') as f:\n",
    "            np.save(f, self.weights)\n",
    "            np.save(f, self.weights_history)            \n",
    "\n",
    "        plt.plot(list(range(self.loss.shape[0])),self.loss,label=\"Training Loss\",color=\"purple\")\n",
    "        plt.plot(list(range(self.val_loss.shape[0])),self.val_loss,label=\"Validation Loss\",color=\"red\")           \n",
    "        plt.xlabel(\"Iteration\"); plt.ylabel(\"Loss(MSE)\")\n",
    "        plt.title(path); plt.legend(); plt.savefig(file_path + '/loss.png'); plt.show() ;plt.clf()\n",
    "        \n",
    "        plt.plot(list(range(self.acc.shape[0])),self.acc,label=\"Training Accuracy\",color=\"blue\")\n",
    "        plt.plot(list(range(self.val_acc.shape[0])),self.val_acc,label=\"Validation Accuracy\",color=\"green\")           \n",
    "        plt.xlabel(\"Iteration\"); plt.ylabel(\"Accuracy\")\n",
    "        plt.title(path); plt.legend(); plt.savefig(file_path + '/accuracy.png'); plt.show() ;plt.clf()        \n",
    "        \n",
    "        plt.plot(list(range(self.miss_classified_train.shape[0])),self.miss_classified_train,label=\"Training Misclassified\",color=\"black\")\n",
    "        plt.plot(list(range(self.miss_classified_valid.shape[0])),self.miss_classified_valid,label=\"Validation Misclassified\",color=\"gold\")           \n",
    "        plt.xlabel(\"Iteration\"); plt.ylabel(\"Misclassified Rate\")\n",
    "        plt.title(path); plt.legend(); plt.savefig(file_path + '/Misclassified.png'); plt.show() ;plt.clf()\n",
    "        \n",
    "        if self.order != 1 :    \n",
    "            cols = [\"Bias\",\"X1\",\"X2\",\"X1^2\",\"X2^2\",\"X1*X2\",\"Label\"]\n",
    "            info = pd.DataFrame(np.append(self.kernel(x_test),y_test,axis=1),columns=cols)\n",
    "            sns.pairplot(info,hue=\"Label\"); plt.savefig(file_path + '/pairplot.png'); plt.show(); plt.clf()\n",
    "        \n",
    "        N =  500\n",
    "        _range_x = np.linspace(int(x_test.T[0].min())-2,int(x_test.T[0].max())+2,N)\n",
    "        _range_y = np.linspace(int(x_test.T[1].min())-2,int(x_test.T[1].max())+2,N)\n",
    "        _range_y, _range_x = np.meshgrid(_range_x, _range_y)\n",
    "        _range_z = self.predict(np.array([np.reshape(_range_x,(N*N,)),np.reshape(_range_y,(N*N,))]).T)\n",
    "        _range_z = np.reshape(_range_z,(N,N))\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        cmap = ListedColormap([\"darkorange\", \"lightseagreen\"])            \n",
    "        c = ax.pcolormesh(_range_x, _range_y, _range_z,cmap=cmap, vmin=-1.5, vmax=1.75)\n",
    "        ax.set_title(path+\" | Test Samples\")\n",
    "        ax.axis([_range_x.min(), _range_x.max(), _range_y.min(), _range_y.max()])\n",
    "         \n",
    "        if self.order == 1:\n",
    "            _range = np.linspace(int(x_test.T[0].min())-1,int(x_test.T[0].max())+1,500)                \n",
    "            for _ in range(0,self.weights_history.shape[0]):\n",
    "                b,w1,w2 = self.weights_history[_]\n",
    "                ax.plot(_range,[-tmp*w1/w2 - b/w2 for tmp in _range],color=\"yellow\",alpha=0.2)\n",
    "                    \n",
    "            b,w1,w2 = self.weights[0],self.weights[1],self.weights[2]\n",
    "            ax.plot(_range,[-tmp*w1/w2 - b/w2 for tmp in _range],color=\"green\",linestyle = 'dashed',label=\"boundary\")  \n",
    "                  \n",
    "            plt.xlabel(\"Feature - 1\")\n",
    "            plt.ylabel(\"Feature - 2\")\n",
    "            \n",
    "        ax.scatter(x_test[(y_test==-1).T[0]].T[0],x_test[(y_test==-1).T[0]].T[1],color=\"darkorange\",alpha=0.4,label=\"Class -1\",edgecolors='black')\n",
    "        ax.scatter(x_test[(y_test==1).T[0]].T[0],x_test[(y_test==1).T[0]].T[1],color=\"lightseagreen\",alpha=0.4,label=\"Class 1\",edgecolors='black')\n",
    "        \n",
    "        plt.legend(); plt.savefig(file_path + '/order-plot.png'); plt.show(); plt.clf()    \n",
    "\n",
    "        \n",
    "        if x_test is not None:\n",
    "            CalculateMetricsAndPlot(y_test,self.predict(x_test),\"Blues\",path,file_path)        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f58f5e3d824a28f35e64a3b79d7f63edde6993a3dcc3aa79d0be3205de7b8a2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
